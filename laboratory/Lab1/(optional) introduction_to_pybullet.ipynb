{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to PyBullet\n",
    "\n",
    "[PyBullet](https://pybullet.org/wordpress/) is a \"rigid body dynamics\" simulator, it means that it can simulate any articulated, rigid, robot. For example our NYU finger but also more complex robots, such as a humanoid, a quadruped or a hand. It can also simulate other objects and several robots at the same time.\n",
    "\n",
    "## How does it work?\n",
    "\n",
    "In a nutshell, every simulator functions as follows:\n",
    "* First a description of the objects and robots to simulate are given, including their dynamic properties (masses, center of mass), their \"boundaries\" (to detect collisions between objects) and graphic files to visualize the robot. The visualization is often different than what is simulated (i.e. we often simplify the geometry of the robot, e.g. using cylinders, for the simulation but display all the details in the visualization)\n",
    "\n",
    "* At each instant of time, the simulator keeps track of all the collisions between all the objects, to know where to compute contact forces. Typically the collisions are simplified to make the simulation fast enough.\n",
    "\n",
    "* The simulator then computes all the forces exerted on all the objects and robots (e.g. gravity, contact between objects, etc) and uses Netwon's law of motion to compute the next position and velocity of all the objects.\n",
    "\n",
    "The user can then decide to apply forces/torques on certain joints, like a motor would do and read all the available information from the simulator to emulate real sensors.\n",
    "\n",
    "As a user, we then need to write a \"controller\" that decides what to do at each simulation step.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's first import pybullet in the notebook\n",
    "import pybullet as p\n",
    "\n",
    "#setup nice plotting\n",
    "%matplotlib notebook\n",
    "\n",
    "# we also import other useful libraries\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib as mp\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we can start pybullet and set a few parameters\n",
    "# an empty simulation window should appear\n",
    "\n",
    "# Connect to pybullet and setup simulation parameters.\n",
    "p.connect(p.GUI)\n",
    "\n",
    "# we set gravity\n",
    "p.setGravity(0, 0, -9.81)\n",
    "# we set the integration step to 1ms (each time we step the simulation it will advance by 1ms)\n",
    "p.setPhysicsEngineParameter(fixedTimeStep=1.0/1000.0, numSubSteps=1)\n",
    "# Disable the gui controller as we don't use them.\n",
    "p.configureDebugVisualizer(p.COV_ENABLE_GUI,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now import our robot, using a [URDF file](http://wiki.ros.org/urdf/XML/model) (Unified Robot Description Format), a commonly used format to describe articulated robots.\n",
    "\n",
    "It describes the links of the robot and the joints connecting the links. It allows to specify the dynamic parameters (mass, center of mass and inertia), the collision model and the visualization.\n",
    "\n",
    "You can take a look at the URDF file of the [NYU finger](./urdf/fingeredu.urdf). We will see in our next lectures how we can describe any robot like that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's load our robot\n",
    "\n",
    "# Zoom onto the robot.\n",
    "p.resetDebugVisualizerCamera(1.0, 50, -35, (0., 0., 0.))\n",
    "\n",
    "# we set the initial position and orientation of the robot\n",
    "robotStartPosition = [0.,0,.0]\n",
    "robotStartOrientation = p.getQuaternionFromEuler([0,0,0])\n",
    "\n",
    "# we load the robot - the robot should be attached to the ground\n",
    "# so we set useFixedBase to True\n",
    "robotId = p.loadURDF('./urdf/fingeredu.urdf', robotStartPosition,\n",
    "                robotStartOrientation, flags=p.URDF_USE_INERTIA_FROM_FILE,\n",
    "                useFixedBase=True)\n",
    "\n",
    "# you should now see our NYU finger in the pybullet window\n",
    "# you should however not be able to do much because the simulation is not running yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can now query some information about the robot\n",
    "nj = p.getNumJoints(robotId)\n",
    "print('the robot has: ' + str(nj) + ' joints\\n')\n",
    "print('the joint names are:')\n",
    "for i in range(nj):\n",
    "    print(p.getJointInfo(robotId, i)[1].decode('UTF-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see that the number of joints of the robot known to PyBullet is not the number of actuated joints in the robot. \n",
    "\n",
    "The first joint \"base_to_finger\" corresponds to a \"fixed joint\" that describe the attachement between the base of the robot and the first join.\n",
    "\n",
    "The last joint \"finger_lower_to_tip_joint\" corresponds to a \"fixed joint\" that allows to attach the fingertip to the leg.\n",
    "\n",
    "These two joints are \"fake\". They are useful for the simulation and to describe the robot, find coordinate frames (we will discuss this in the next lectures!)\n",
    "\n",
    "The joints we care about are:\n",
    "* finger_base_to_upper_joint which is the \"shoulder\"\n",
    "* finger_upper_to_middle_joint which is the \"hip\"\n",
    "* finger_middle_to_lower_joint which is the \"elbow\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are going to store the ids of the joints we care about\n",
    "joint_names = [\n",
    "            'finger_base_to_upper_joint',\n",
    "            'finger_upper_to_middle_joint',\n",
    "            'finger_middle_to_lower_joint',\n",
    "        ]\n",
    "\n",
    "# a map from names to ids\n",
    "bullet_joint_map = {}\n",
    "for ji in range(p.getNumJoints(robotId)):\n",
    "    bullet_joint_map[p.getJointInfo(robotId, ji)[1].decode('UTF-8')] = ji\n",
    "\n",
    "# a list of ids we are interested in\n",
    "bullet_joint_ids = np.array([bullet_joint_map[name] for name in joint_names])\n",
    "num_joints = bullet_joint_ids.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can now run the simulation of the robot for 10 seconds\n",
    "\n",
    "# first we need to disable the velocity control on the joints - we set 0 torques on each joint\n",
    "p.setJointMotorControlArray(robotId, bullet_joint_ids, p.VELOCITY_CONTROL, forces=np.zeros(num_joints))\n",
    "\n",
    "run_time = 10.\n",
    "dt = 0.001\n",
    "num_steps = int(run_time/dt)\n",
    "\n",
    "### this is the simulation loop ###\n",
    "### we do one step of simulation num_steps times ###\n",
    "for i in range(num_steps):\n",
    "    time.sleep(dt)\n",
    "    p.stepSimulation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can now reset the robot to a different position and simulate again\n",
    "# now we will also read the joint position and velocities directly from the simulator\n",
    "new_desired_position = [0.0,1.,1.]\n",
    "for i in range(num_joints):\n",
    "    p.resetJointState(robotId, i+1, new_desired_position[i], 0.)\n",
    "\n",
    "measured_positions = np.zeros([num_steps,3])\n",
    "measured_velocities = np.zeros_like(measured_positions)\n",
    "\n",
    "\n",
    "### this is the simulation loop ###\n",
    "### we do one step of simulation num_steps times ###\n",
    "for i in range(num_steps):\n",
    "    time.sleep(dt)\n",
    "    p.stepSimulation()\n",
    "    \n",
    "    # we access the joints and read each joint position and velocity #\n",
    "    joint_states = p.getJointStates(robotId, bullet_joint_ids)\n",
    "    for j in range(num_joints):\n",
    "        measured_positions[i,j] = joint_states[j][0]\n",
    "        measured_velocities[i,j] = joint_states[j][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now plot the position of each joint as a function of time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we create the time vector (as we simulated for 10 seconds)\n",
    "time = np.linspace(0., 10., num=num_steps)\n",
    "\n",
    "# we create a figure using matplotlib\n",
    "plt.figure(figsize=[6, 12])\n",
    "\n",
    "# for each joint we plot the measured position as a function of time\n",
    "for i in range(3):\n",
    "    plt.subplot(3,1,i+1)\n",
    "    plt.plot(time, measured_positions[:,i])\n",
    "    plt.ylabel(joint_names[i] + ' [rad]')\n",
    "\n",
    "# adding some labels\n",
    "plt.xlabel('Time[s]')\n",
    "plt.title('joint positions')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now plot the velocities of each joint as a function of time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we do the same for velocities\n",
    "plt.figure(figsize=[6, 12])\n",
    "for i in range(3):\n",
    "    plt.subplot(3,1,i+1)\n",
    "    plt.plot(time, measured_velocities[:,i])\n",
    "    plt.ylabel(joint_names[i] + ' [rad/s]')\n",
    "plt.xlabel('Time[s]')\n",
    "plt.title('joint velocities')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyBullet is a very complete simulator and we only introduce some very basic functionalities. For more information about the API of the simulator please check [this page](https://docs.google.com/document/d/10sXEhzFRSnvFcl3XxNGhnD4N2SedqwdAvK3dsihxVUA/edit#heading=h.2ye70wns7io3)\n",
    "\n",
    "More information about the simulator, robot models, etc can be found on the [simulator website](https://pybullet.org/wordpress/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "manipulation_and_locomotion_class_work",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16 | packaged by conda-forge | (default, Feb  1 2023, 15:53:35) [MSC v.1929 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "e3d020f828c7b657823432f30379f5f035f7fc5e9ca5b3fc0a7e69cded9ebebc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
